{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "z5mw6NzFyOIv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyIjfmDZynsl"
      },
      "source": [
        "Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "XNuyV8w168az"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return (1.0 / (1.0 + np.exp(-x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "VRGJxPNc69Rm"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "    return ((np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "tg6-JHALyqr6"
      },
      "outputs": [],
      "source": [
        "def ReLU(x):\n",
        "    return np.maximum(x,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "7rKo5q0I7Dg4"
      },
      "outputs": [],
      "source": [
        "def LReLU(x, a = 0.1):\n",
        "    return np.maximum(np.multiply(a, x), x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BckNuxHAytVl"
      },
      "source": [
        "Derivatives of Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "OIe3SRfxyzSp"
      },
      "outputs": [],
      "source": [
        "def d_ReLU(x):\n",
        "    return np.multiply((x > 0), np.ones(np.shape(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "zzrX4tJ385EE"
      },
      "outputs": [],
      "source": [
        "def d_sigmoid(x):\n",
        "    y = np.multiply(x, (1.0 - x))\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "a-PwJ-ol88QP"
      },
      "outputs": [],
      "source": [
        "def d_tanh(x):\n",
        "    return(1 - np.multiply(x, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "w9rtr69m8_ZV"
      },
      "outputs": [],
      "source": [
        "def d_LReLU(x, a = 0.1):\n",
        "    return (((x > 0) * np.ones(np.shape(x))) + ((x < 0) * np.full(np.shape(x), a)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W42MPhM9y32d"
      },
      "source": [
        "Error Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "2Od9mGXby8jv"
      },
      "outputs": [],
      "source": [
        "def MSE(y_hat, y):\n",
        "    return np.mean((((y_hat - y) ** 2) / 2.0), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "V7UWrKv_80SM"
      },
      "outputs": [],
      "source": [
        "# mean absolute percentage error\n",
        "def MAPE(y_hat, y):\n",
        "    return np.mean(np.absolute(np.divide((y_hat - y), y_hat)), axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlJrrLM7y_Rx"
      },
      "source": [
        "Normalization Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "tCOrVQARzCYC"
      },
      "outputs": [],
      "source": [
        "def normalisation(x):\n",
        "  mean = np.mean(x, axis=0);\n",
        "  sigma = np.std(x, axis=0);\n",
        "  return (x-mean)/sigma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvZe2rV_zkDl"
      },
      "source": [
        "Initializing the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "tdeAavxmzsHw"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(Features, HiddenLayerNodes, noOfLayers):\n",
        "  params = {}\n",
        "\n",
        "  #Input Layer\n",
        "  W1 = np.random.randn(HiddenLayerNodes, Features)\n",
        "  b1 = np.zeros((HiddenLayerNodes, 1))\n",
        "  params.update({'W1': W1})\n",
        "  params.update({'b1': b1})\n",
        "\n",
        "  for layer in range(noOfLayers-1):\n",
        "    W_layer = np.random.randn(HiddenLayerNodes, HiddenLayerNodes)\n",
        "    b_layer = np.zeros((HiddenLayerNodes, 1))\n",
        "\n",
        "    params.update({'W'+str(layer+2): W_layer})\n",
        "    params.update({'b'+str(layer+2): b_layer})\n",
        "\n",
        "\n",
        "  #Output Layer\n",
        "  W_out = np.random.randn(1, HiddenLayerNodes)\n",
        "  b_out = np.zeros((1, 1))\n",
        "  params.update({'W'+str(noOfLayers+1): W_out})\n",
        "  params.update({'b'+str(noOfLayers+1): b_out})\n",
        "\n",
        "\n",
        "  return params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOZ5P0i6zet7"
      },
      "source": [
        "Forward Propogation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "ETZItj3s3Qnv"
      },
      "outputs": [],
      "source": [
        "def forward_propagation(Input, y_expected, noOfLayers, params, Activations, Error='MSE'):\n",
        "  '''\n",
        "  Input : Features * TrainingExamples\n",
        "  W1 : HiddenLayerNodes * Features\n",
        "  b1 : HiddenLayerNodes * 1\n",
        "  A1 : HiddenLayerNodes * TrainingExamples\n",
        "\n",
        "  Wi : HiddenLayerNodes * HiddenLayerNodes    [OutputLayerNodes = 1]\n",
        "  bi : HiddenLayerNodes * 1\n",
        "  Ai : HiddenLayerNodes * TrainingExamples\n",
        "\n",
        "  W_L+1 : 1 * HiddenLayerNodes\n",
        "  b_L+1 : 1 * 1\n",
        "  A_L+1 : 1 * TrainingExamples\n",
        "\n",
        "  '''\n",
        "\n",
        "  Features, TrainingExamples = Input.shape\n",
        "  HiddenLayerNodes = params['W1'].shape[0]\n",
        "  cache = {}\n",
        "  cache.update({'A0':Input})\n",
        "\n",
        "  for layer in range(1, noOfLayers+1):\n",
        "      W_i = params['W'+str(layer)]\n",
        "      b_i = params['b'+str(layer)]\n",
        "\n",
        "      A_prev = cache['A'+str(layer-1)]\n",
        "      Z_i = W_i @ A_prev + b_i\n",
        "      A_i = np.zeros((HiddenLayerNodes, TrainingExamples))\n",
        "\n",
        "      Activation_i = Activations[layer-1]\n",
        "      if Activation_i == 'sigmoid':\n",
        "        A_i = sigmoid(Z_i)\n",
        "      elif Activation_i == 'tanh':\n",
        "        A_i = tanh(Z_i)\n",
        "      elif Activation_i == 'ReLU':\n",
        "        A_i = ReLU(Z_i)\n",
        "      elif Activation_i == 'LReLU':\n",
        "        A_i = LReLU(Z_i)\n",
        "      else:\n",
        "        print(\"Invalid Activation for Layer \", layer)\n",
        "        return\n",
        "\n",
        "      cache.update({'A'+str(layer) : A_i})\n",
        "  \n",
        "\n",
        "  #output layer\n",
        "  W_out = params['W'+str(noOfLayers+1)]\n",
        "  b_out = params['b'+str(noOfLayers+1)]\n",
        "  A_prev = cache['A'+str(noOfLayers)]\n",
        "  Z_out =  W_out @ A_prev + b_out\n",
        "  Activation_out = Activations[noOfLayers]\n",
        "\n",
        "  if Activation_out == 'sigmoid':\n",
        "    A_out = sigmoid(Z_out)\n",
        "  elif Activation_out == 'tanh':\n",
        "    A_out = tanh(Z_out)\n",
        "  elif Activation_out == 'ReLU':\n",
        "    A_out = ReLU(Z_out)\n",
        "  elif Activation_out == 'LReLU':\n",
        "    A_out = LReLU(Z_out)\n",
        "  else:\n",
        "    print(\"Invalid Activation for Layer \", noOfLayers)\n",
        "    return\n",
        "\n",
        "  cache.update({'A'+str(noOfLayers+1) : A_out})\n",
        "\n",
        "\n",
        "  error = 0\n",
        "\n",
        "  if Error == \"MSE\":\n",
        "     error = MSE(A_out,y_expected)\n",
        "  elif Error == \"MAPE\":\n",
        "     error = MAPE(A_out, y_expected)\n",
        "  else:\n",
        "    print(\"Invalid Error Function\")\n",
        "    return\n",
        "\n",
        "  return cache, error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NCC0pWTQXBz"
      },
      "source": [
        "Backward Propogation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "sEKtwMj1QZp0"
      },
      "outputs": [],
      "source": [
        "def backward_propagation(params, cache, y_expected, Activations, noOfLayers, learning_rate = 0.1, Error = 'MSE'):\n",
        "\n",
        "  A_out = cache['A'+str(noOfLayers+1)]\n",
        "  d_A_out = np.zeros(np.shape(A_out))\n",
        "  d_Z_out = np.zeros(np.shape(A_out)) # 1 * TrainingExamples\n",
        "  d_W_out = cache['A'+str(noOfLayers)] # HiddenLayerNodes * TrainingExamples\n",
        "\n",
        "  if Error == 'MSE':\n",
        "    d_A_out = (y_expected - A_out)/np.shape(A_out)[1]\n",
        "  elif Error == 'MAPE':\n",
        "    d_A_out = np.divide(np.sign((y_expected - A_out)), np.absolute(A_out))\n",
        "  else :\n",
        "    print(\"Invalid Error Function\")\n",
        "    return\n",
        "    \n",
        "  Activation_out = Activations[noOfLayers]\n",
        "\n",
        "  if Activation_out == 'sigmoid':\n",
        "    d_Z_out = d_sigmoid(A_out)\n",
        "  elif Activation_out == 'tanh':\n",
        "    d_Z_out = d_tanh(A_out)\n",
        "  elif Activation_out == 'ReLU':\n",
        "    d_Z_out = d_ReLU(A_out)\n",
        "  elif Activation_out == 'LReLU':\n",
        "    d_Z_out = d_LReLU(A_out)\n",
        "\n",
        "  else:\n",
        "    print(\"Invalid Activation for Layer \", noOfLayers)\n",
        "    return\n",
        "\n",
        "\n",
        "  delta_W_out = np.transpose(np.multiply(learning_rate , d_W_out @ np.transpose(np.multiply(d_A_out, d_Z_out))))\n",
        "  delta_b_out = np.mean(np.multiply(learning_rate , np.transpose(np.multiply(d_A_out, d_Z_out))), axis = 0).reshape(1,1)\n",
        "\n",
        "  reverse_cache = {}\n",
        "\n",
        "  reverse_cache.update({'delta_W'+str(noOfLayers+1): delta_W_out})\n",
        "  reverse_cache.update({'delta_b'+str(noOfLayers+1): delta_b_out})\n",
        "\n",
        "\n",
        "  # used for storing for backprop through layers\n",
        "  back = np.multiply(d_A_out, d_Z_out)  # 1 * Trainingexamples\n",
        "\n",
        "  for layer in range(noOfLayers, 0, -1):\n",
        "    d_A_i = params['W'+str(layer+1)] # 1 * HiddenLayerNodes || HiddenLayerNodes * HiddenLayerNodes \n",
        "    A_i = cache['A'+str(layer)]\n",
        "    d_Z_i = np.zeros(np.shape(A_i))\n",
        "    \n",
        "    if Activations[layer-1] == 'sigmoid':\n",
        "      d_Z_i = d_sigmoid(A_i)\n",
        "    elif Activations[layer-1] == 'tanh':\n",
        "      d_Z_i = d_tanh(A_i)\n",
        "    elif Activations[layer-1] == 'ReLU':\n",
        "      d_Z_i = d_ReLU(A_i)\n",
        "    elif Activations[layer-1] == 'LReLU':\n",
        "      d_Z_i = d_LReLU(A_i) \n",
        "\n",
        "    #back1 - 1 * Training \n",
        "    #d_A_i1 - 1* Hidden\n",
        "    #d_Z_i1 - Hidden * Training\n",
        "    #\n",
        "    #d_A_prev1 - Hidden * Training\n",
        "\n",
        "\n",
        "    back_temp = np.multiply((np.transpose(d_A_i) @ back),d_Z_i) # HiddenLayerNodes * TrainingExamples\n",
        "    delta_W_i = np.multiply(learning_rate, back_temp) @ np.transpose(cache['A'+str(layer-1)]) # HiddenLayerNodes * HiddenLayerNodes\n",
        "    delta_b_i = np.mean(np.multiply(learning_rate, back_temp), axis = 1).reshape(A_i.shape[0],1) # HiddenLayerNodes * 1\n",
        "\n",
        "    reverse_cache.update({'delta_W'+str(layer): delta_W_i})\n",
        "    reverse_cache.update({'delta_b'+str(layer): delta_b_i})\n",
        "\n",
        "    back = back_temp\n",
        "\n",
        "\n",
        "  return reverse_cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SCDqG2_j_2p"
      },
      "source": [
        "Separation and observation of data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKHxWgL_yFrX",
        "outputId": "253c8d3e-ffd4-4229-a55a-22e4e57bca17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train:(6, 67517)\n",
            "Y_train:(1, 67517)\n",
            "X_val:(6, 19291)\n",
            "Y_val:(1, 19291)\n",
            "X_test:(6, 9645)\n",
            "Y_test:(1, 9645)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('weatherHistory.csv')\n",
        "df = df.drop(['Formatted Date', 'Precip Type', 'Summary', 'Daily Summary', 'Loud Cover'], axis=1)\n",
        "#df.head()\n",
        "\n",
        "#split into training and test\n",
        "test=df.sample(frac=0.1,random_state=25)\n",
        "\n",
        "#random state is a seed value for same split at each run\n",
        "train_val=df.drop(test.index)\n",
        "validation = train_val.sample(frac=2/9, random_state=25)\n",
        "train = train_val.drop(validation.index)\n",
        "\n",
        "# print(train.head())\n",
        "# print(test.head())\n",
        "# print(val.head())\n",
        "\n",
        "(X_train, Y_train) = train.values[:, 1:], np.reshape(train.values[:, 0], (-1, 1))\n",
        "X_train = np.transpose(X_train)\n",
        "Y_train = np.transpose(Y_train)\n",
        "\n",
        "\n",
        "print('X_train:' + str(X_train.shape))\n",
        "print('Y_train:' + str(Y_train.shape))\n",
        "\n",
        "\n",
        "(X_val, Y_val) = validation.values[:, 1:], np.reshape(validation.values[:, 0], (-1, 1))\n",
        "X_val = np.transpose(X_val)\n",
        "Y_val = np.transpose(Y_val)\n",
        "\n",
        "\n",
        "print('X_val:' + str(X_val.shape))\n",
        "print('Y_val:' + str(Y_val.shape))\n",
        "\n",
        "(X_test, Y_test) = test.values[:, 1:], np.reshape(test.values[:, 0], (-1, 1))\n",
        "X_test = np.transpose(X_test)\n",
        "Y_test = np.transpose(Y_test)\n",
        "\n",
        "# #print(Y_test)\n",
        "\n",
        "# #normalisation\n",
        "for column in range(X_train.shape[0]):\n",
        "  X_train[column] = normalisation(X_train[column])\n",
        "\n",
        "for column in range(X_val.shape[0]):\n",
        "  X_val[column] = normalisation(X_val[column])\n",
        "\n",
        "for column in range(X_test.shape[0]):\n",
        "  X_test[column] = normalisation(X_test[column])\n",
        "print('X_test:' + str(X_test.shape))\n",
        "print('Y_test:' + str(Y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGi9rqbvzpZw"
      },
      "source": [
        "Updating the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "Ec4eThQfzsgI"
      },
      "outputs": [],
      "source": [
        "def update_parameters(params, reverse_cache, noOfLayers):\n",
        "  for layer in range(1, noOfLayers+1):\n",
        "    W_i = params['W'+str(layer)]\n",
        "    b_i = params['b'+str(layer)]\n",
        "\n",
        "    delta_W_i = reverse_cache['delta_W'+str(layer)]\n",
        "    delta_b_i = reverse_cache['delta_b'+str(layer)]\n",
        "\n",
        "    #learning_rate taken into account in the backward propagation\n",
        "    W_i = W_i + delta_W_i\n",
        "    b_i = b_i + delta_b_i\n",
        "\n",
        "    params.update({'W'+str(layer): W_i})\n",
        "    params.update({'b'+str(layer): b_i})\n",
        "\n",
        "  return params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNEXoSxU0njc"
      },
      "source": [
        "Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "j2VZkqDa0qYj"
      },
      "outputs": [],
      "source": [
        "def training(Input, y_expected, Input_validation, y_expected_validation, Activations, noOfLayers = 1, learning_rate = 0.01, Error = 'MSE', HiddenLayerNodes = 20, epochs = 2000):\n",
        "    Features, TrainingExamples = Input.shape\n",
        "    params = initialize_parameters(Features, HiddenLayerNodes, noOfLayers)\n",
        "    errors = []\n",
        "    val_errors = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      #forward prop\n",
        "      cache, error = forward_propagation(Input, y_expected, noOfLayers, params, Activations, Error)\n",
        "\n",
        "      #validation forward prop\n",
        "      val_cache, val_error = forward_propagation(Input_validation, y_expected_validation, noOfLayers, params, Activations, Error)\n",
        "\n",
        "      #back prop\n",
        "      reverse_cache = backward_propagation(params, cache, y_expected, Activations, noOfLayers, learning_rate)\n",
        "\n",
        "      #update\n",
        "      params = update_parameters(params, reverse_cache, noOfLayers)\n",
        "\n",
        "      errors.append(error)\n",
        "      val_errors.append(val_error)\n",
        "      if epoch % 100 == 1:\n",
        "        print(\"The training error after\", epoch, \"Iterations is\", error)\n",
        "        print(\"The validation error after\", epoch, \"Iterations is\", val_error)\n",
        "\n",
        "      #conversion to array\n",
        "\n",
        "    err = np.array(errors)\n",
        "    val_err = np.array(val_errors)\n",
        "    return params, err, val_err\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_v8OhX331M9"
      },
      "source": [
        "Testing the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "0x0pkzVH331b"
      },
      "outputs": [],
      "source": [
        "def testing(Input_test, y_expected_test, params, Activations, noOfLayers = 1, Error='MSE'):\n",
        "  cache, error = forward_propagation(Input_test, y_expected_test, noOfLayers, params, Activations, Error)\n",
        "\n",
        "  y_out = cache['A'+str(noOfLayers+1)]\n",
        "\n",
        "  return y_out, error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyD1xkXk4oyi"
      },
      "source": [
        "Plotting the training error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MVxU65_W4tmX",
        "outputId": "6e47dce6-ca2e-47ee-9979-885f8c77055a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training error after 1 Iterations is [101.75117046]\n",
            "The validation error after 1 Iterations is [100.67580389]\n",
            "The training error after 101 Iterations is [7.01196873]\n",
            "The validation error after 101 Iterations is [6.82062824]\n",
            "The training error after 201 Iterations is [5.53381662]\n",
            "The validation error after 201 Iterations is [5.37195111]\n",
            "The training error after 301 Iterations is [4.88140186]\n",
            "The validation error after 301 Iterations is [4.7547933]\n",
            "The training error after 401 Iterations is [4.58083414]\n",
            "The validation error after 401 Iterations is [4.47404932]\n",
            "The training error after 501 Iterations is [4.38505402]\n",
            "The validation error after 501 Iterations is [4.29716128]\n",
            "The training error after 601 Iterations is [4.2477216]\n",
            "The validation error after 601 Iterations is [4.1687882]\n",
            "The training error after 701 Iterations is [4.1445937]\n",
            "The validation error after 701 Iterations is [4.07460242]\n",
            "The training error after 801 Iterations is [4.05905422]\n",
            "The validation error after 801 Iterations is [4.00014629]\n",
            "The training error after 901 Iterations is [3.99319306]\n",
            "The validation error after 901 Iterations is [3.93875468]\n",
            "The training error after 1001 Iterations is [3.9418731]\n",
            "The validation error after 1001 Iterations is [3.8923879]\n",
            "The training error after 1101 Iterations is [3.89966052]\n",
            "The validation error after 1101 Iterations is [3.85323054]\n",
            "The training error after 1201 Iterations is [3.8634009]\n",
            "The validation error after 1201 Iterations is [3.81853617]\n",
            "The training error after 1301 Iterations is [3.83169843]\n",
            "The validation error after 1301 Iterations is [3.78920731]\n",
            "The training error after 1401 Iterations is [3.80249971]\n",
            "The validation error after 1401 Iterations is [3.76203897]\n",
            "The training error after 1501 Iterations is [3.77523202]\n",
            "The validation error after 1501 Iterations is [3.73676424]\n",
            "The training error after 1601 Iterations is [3.75054276]\n",
            "The validation error after 1601 Iterations is [3.71491901]\n",
            "The training error after 1701 Iterations is [3.72795137]\n",
            "The validation error after 1701 Iterations is [3.69443887]\n",
            "The training error after 1801 Iterations is [3.70699082]\n",
            "The validation error after 1801 Iterations is [3.67628926]\n",
            "The training error after 1901 Iterations is [3.68733432]\n",
            "The validation error after 1901 Iterations is [3.65956379]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXXUlEQVR4nO3de5BkZ3nf8e/TPTO72tVlV9IgFkl4FyxMbcVFUKaIUmDisjAWwkYKcWRRVFhjVamSkBiCb3JIBVelXGViB9tUHLlkhFkSjAEZIpXLsVFkESAuyRldAF3RSqBbVqvBuqJd7Vz6yR/n7dnTszO7O9Mz09Nnv5+qqXPpc3n69Myv33n79DmRmUiSmqU16AIkSavPcJekBjLcJamBDHdJaiDDXZIaaGTQBQCcffbZuXPnzkGXIUlD5Y477vh+Zo4v9tiGCPedO3cyOTk56DIkaahExKNLPWa3jCQ1kOEuSQ1kuEtSAxnuktRAhrskNZDhLkkNZLhLUgMNdbhnJl+cfJxD03ODLkWSNpShDvd7/98L/MoN3+JXbvjmoEuRpA1lqMN9bKQq/xv7vj/gSiRpYxnqcO/eROq5gzODLUSSNpjhDne8RaAkLWaow73TGXQFkrQxDXe4127u/fKMZ8xIUtdQh3st23n24PTgCpGkDWaow73ecn/mJcNdkrqGOtzrH6d6xowkHTHU4V5vuf/g8OwAK5GkjWWowz1r4X5w2nCXpK6hDvdOrV/mB4c9W0aSuoY63Otnyxy0W0aS5g11uNf73F8y3CVpXmPC3W4ZSTpiqMO93i0zPWe4S1LXUId7veU+PeuFZiSpa6jDvaflbrhL0ryhDveelvuc4S5JXUMd7rbcJWlxQx3u3ZZ7K2B6zht3SFLXUId7t+W+aaTN9Kxny0hS13HDPSI+FRFPR8Q9tXlnRsTNEfFQGW4v8yMiPhER+yLiWxFx4VoW3225bx5t2S0jSTUn0nL/NHDJgnnXALdk5gXALWUa4B3ABeXnauDa1Slzcd1ry2webfuBqiTVHDfcM/NrwDMLZl8G7C3je4HLa/M/k5XbgG0RsWO1il2kNqCEuy13SZq30j73czJzfxl/CjinjJ8LPF5b7oky7ygRcXVETEbE5NTU1IqK6Mz3ubeY8QNVSZrX9weqWTWfl52smXldZk5k5sT4+PjK9l12OzZin7sk1a003A90u1vK8Oky/0ng/Npy55V5a6Lbch9tt5jr2HKXpK6VhvtNwJ4yvge4sTb/feWsmYuA52vdN6uu2+c+2g7m0nCXpK6R4y0QEZ8Dfhw4OyKeAD4K/BbwhYi4CngUuKIs/hfApcA+4CDw/jWoeV5nPtxtuUtS3XHDPTPfs8RDFy+ybAIf6LeoE9VtrI+0gllPhZSkeUP9DdV6n7sNd0k6YsjDvXTLjLSY7dhyl6SuoQ73+Q9UW2GfuyTVDHW4d/N8xA9UJanHUId7Luhz7xjwkgQMebh3aue5A57rLknFUId7t899pFU9jY7hLknAkId7txemXZ6F2S5JlaEO927LvdWKMj3IaiRp4xjqcO/UvqFaTZvukgRDH+5VmLfDcJekuqEO95zvc6+ehtEuSZWhDvf5lnv3A1WvQCBJwJCH+2vGT+WdP7qD0banQkpS3VCH+0/uPoc/eO+FbB5tA4a7JHUNdbh3lZNl7HOXpKIR4R6eLSNJPRoR7q3wS0ySVNeIcC/ZbstdkopGhPt8n7vZLklAQ8LdPndJ6tWMcC9Ds12SKo0Idz9QlaRezQj38izslpGkSjPC3T53SerRiHDv8v7YklRpRLh3W+5egECSKn2Fe0T824i4NyLuiYjPRcTmiNgVEbdHxL6I+HxEjK1WsUs50i2z1nuSpOGw4nCPiHOBXwQmMvPvAW3gSuBjwO9m5g8DzwJXrUahx66lGtrnLkmVfrtlRoBTImIE2ALsB34CuKE8vhe4vM99HJfnuUtSrxWHe2Y+CfwO8BhVqD8P3AE8l5mzZbEngHMXWz8iro6IyYiYnJqaWmkZZVvdmvrajCQ1Rj/dMtuBy4BdwKuArcAlJ7p+Zl6XmROZOTE+Pr7SMrrVVNv0A1VJAvrrlnkb8N3MnMrMGeBLwJuBbaWbBuA84Mk+azwuW+6S1KufcH8MuCgitkR15a6LgfuAW4GfLcvsAW7sr8Tji+MvIkknlX763G+n+uD0TuDbZVvXAb8GfDgi9gFnAdevQp3HFGG8S1LdyPEXWVpmfhT46ILZjwBv6me7K2W3jCRVGvEN1SPfTzXdJQmaEu5+oCpJPZoV7oMtQ5I2jGaEe/c8d5vukgQ0JNyx5S5JPRoR7l5bRpJ6NSPcvZ67JPVoRriXoS13Sao0I9ztc5ekHs0Id68uI0k9GhHuXXbLSFKlEeF+5BuqprskQVPCvQyNdkmqNCLc8doyktSjEeEe3mZPkno0I9ztl5GkHs0I9zI02yWp0oxwj+5VIQdciCRtEA0J92pon7skVZoR7mVoy12SKs0Id68+IEk9GhHuXTbcJanSkHD3NnuSVNeIcPeSv5LUqxnh3h0x3SUJaEq4h5cfkKS6ZoR7GdrlLkmVvsI9IrZFxA0R8UBE3B8R/ygizoyImyPioTLcvlrFLl1HNTTcJanSb8v994G/zMzXA28A7geuAW7JzAuAW8r0mjpyVUhJEvQR7hFxBvBW4HqAzJzOzOeAy4C9ZbG9wOX9Fnn8Wqqhp0JKUqWflvsuYAr444i4KyI+GRFbgXMyc39Z5ingnMVWjoirI2IyIianpqb6KOMIo12SKv2E+whwIXBtZr4ReIkFXTBZNaUXzdzMvC4zJzJzYnx8vI8yvPyAJC3UT7g/ATyRmbeX6Ruowv5AROwAKMOn+yvxxNkrI0mVFYd7Zj4FPB4RP1JmXQzcB9wE7Cnz9gA39lXhCQhv1yFJPUb6XP/fAJ+NiDHgEeD9VG8YX4iIq4BHgSv63MdxeSqkJPXqK9wz825gYpGHLu5nu8vltWUkqVdDvqHqbfYkqa4Z4e5t9iSpRzPCvQxtuUtSpRnhbp+7JPVoRLh7JyZJ6tWIcPcbqpLUqxnhPugCJGmDaUS4d9krI0mVRoS7t9mTpF7NCPcytOUuSZVmhLvXlpGkHs0Id2+zJ0k9mhHu3mZPkno0Ity7jHZJqjQi3MN7dUhSj4aEu6dCSlJdM8K9DO1yl6RKM8Ld6w9IUo9GhHuXDXdJqjQi3L3NniT1aka4e5s9SerRjHAvQ1vuklRpRLjjbfYkqUcjwj3wymGSVNeMcLflLkk9mhHuZWjDXZIqzQj37uUHTHdJAlYh3COiHRF3RcSfl+ldEXF7ROyLiM9HxFj/ZR6nhjI02iWpshot9w8C99emPwb8bmb+MPAscNUq7OOYvPyAJPXqK9wj4jzgncAny3QAPwHcUBbZC1zezz6Ww14ZSar023L/PeBXgU6ZPgt4LjNny/QTwLmLrRgRV0fEZERMTk1N9VWEt9mTpF4rDveI+Gng6cy8YyXrZ+Z1mTmRmRPj4+MrLaMUM7/N/rYjSQ0x0se6bwbeFRGXApuB04HfB7ZFxEhpvZ8HPNl/mcdmn7sk9Vpxyz0zfz0zz8vMncCVwF9n5nuBW4GfLYvtAW7su8rj8Dx3Seq1Fue5/xrw4YjYR9UHf/0a7KOHt9mTpF79dMvMy8yvAl8t448Ab1qN7Z4oW+6S1Ksh31Cthma7JFWaEe7eiUmSejQj3L0TkyT1aES4S5J6NSrc7ZaRpEojwt0vMUlSr0aEe7uk+1zHprskQVPCvRVEwOxc5/gLS9JJoBHhHhGMtltMz9lylyRoSLgDjLVbzNhylySgQeE+2g7DXZKKBoW7LXdJ6mpUuE/P2ucuSdCgcB8baTFty12SgAaF+2g7mJk13CUJGhXu9rlLUldjwt1uGUk6YlXuxLQR3PXYc4MuQZI2jMa03CVJRxjuktRAjQn3f/njr2W07bV/JQkaFO4jrfCSv5JUNCbcWxF0EtLbMUlSc8J9pOUNOySpqzHh3i797bOGuyQ1KNzLrfY6dstI0srDPSLOj4hbI+K+iLg3Ij5Y5p8ZETdHxENluH31yl1au2XLXZK6+mm5zwK/lJm7gYuAD0TEbuAa4JbMvAC4pUyvuW64dwx3SVp5uGfm/sy8s4y/CNwPnAtcBuwti+0FLu+3yBMx2q6eysszXl9Gklalzz0idgJvBG4HzsnM/eWhp4BzVmMfx3Pu9lMAePzZg+uxO0na0PoO94g4Ffgz4EOZ+UL9saxOOl+0nyQiro6IyYiYnJqa6rcMto5V10A7bMtdkvoL94gYpQr2z2bml8rsAxGxozy+A3h6sXUz87rMnMjMifHx8X7KAJi/9IDXdJek/s6WCeB64P7M/HjtoZuAPWV8D3Djyss7cd0+d8Ndkvq7nvubgX8OfDsi7i7z/h3wW8AXIuIq4FHgiv5KPDFjI91w92wZSVpxuGfmN4ClLsN48Uq3u1K23CXpiMZ8Q7Xb5z7tTbIlqTnhftqmUQBeeHlmwJVI0uA1JtxPP2WEsXaLqR8cHnQpkjRwjQn3iGDbllGee8mWuyQ1JtwBtm8Z49mD04MuQ5IGrlHhvm3LKM8dtOUuSY0K9zO3jvGMLXdJala4n7vtFJ589pCX/ZV00mtUuO8a38qhmTkOvPjyoEuRpIFqVriftRWAh59+acCVSNJgNSrcd7/qdCLgrseeHXQpkjRQjQr3bVvGeP0rT+fWBxe9yrAknTQaFe4APzdxHnc+9hz/Z9/3B12KJA1M48L9Pf/w1bzqjM389l89SHUjKEk6+TQu3DeNtPnFiy/g7sef45Nf/27PY3Od5D/++X389QMHBlSdJK2PxoU7wBUT5/OTu8/hN//ifn75i99k6sXDvHR4lp//47/l+m98l1/49CRff6j/+7ZK0kYVG6HrYmJiIicnJ1d1my/PzPHv/8c93HDHEz3zX//K03jgqRc5a+sYX/5Xb+bVZ21Z1f1K0nqJiDsyc2KxxxrZcgfYPNrmd/7ZG7j2vRdyxinVtd4/+jO7+csPvZVbfukfM5fJOz/xdf7oa48MuFJJWn2Nbbkfz52PPcu7/+vfzE+PtIJLf3QHV71lF699xalsGW0TUV1KWJI2omO13E/acAd4/JmDvPvav2HqxRO/wcfm0RY/N3E+73/zLl595hZaLcNf0mAY7seRmXz1O1N8/Cvf4cEDL67oPqw7ztjM7h2n87pXnsZZW8c4c+sYZ526iR1nbGb81E1s2dRm00h7DaqXdLIy3FfJ84dm+JPbH+O/3/Yo+58/xHIvPjnWbrFlU5utYyOcMtbmlNH2kWEZ3zzaYtNIm7GRFptHq+mxdotNI9X80ZHglNE27VaL0XYwNtJitF39jLSq6ZFWHJnXDkZbLdrtmJ/fsrtJagTDfZ3MznV45uA0Dx34AS8cmuHFw7ME8MLLs7x0uPxMz3Lw8ByHZuY4OF0ND03P8fJMNf7yTIfDs3NMz3Y4vIL/IE7USCsYaQcjrRbtVhX87dpP73T1htHqzo+g1YJWVI+3ImgFtfEyvxW0o1qutcR6QPXZBlGGzH/WEQCLPdYzHUuuv+S2yzRl/dZR26oWXHx/1TT1dYBW6+jtLrU+C+sv81tx9HYXrn/08Vj8uC22/lHHY4naWnGc9U+wtlbttWF+fydYW/21sSGypGOF+8h6F9NkI+0WrzhtM684bfOqbC8zOTzbYXquw+ES+jNzyaHpOeY6yfRch+nZDrOdDjNzHWbmkpm5DrNz1WOzc8ls58hwZi6ZnUvmMpmd6zDXSWY7yVynWq+T5fFOWaaTzJXljyxbrdfJ6s1sLqvxTtlOJ6uf7jLz42V6Lqvx7jABErI832oISZZh9/Ej0/XldPJY6s3hyBviIm981N6QFpnf+0Zbtlfb3/z4/Lzex3uXOXrd+npHvUWV/X7wba/jXW941coOyjEY7htYRJSumTaszvtF42QuHvrdNwM4+s2i582hvAEttv6RN51F1l9k252eN5368rX1j1NbZ37bC9ZfZm29+1v4hrhEbWU5anUsXP/oN9qFb8TZU3NnwXaP3t/C43H0Y51csN1F1u9pICx63Jdef/541BoL5dnO11yeem28+4SPPFb/nazPy95Fe5bLhG3lVO3VZrhrqHVbZGVqkKVIG0pjv8QkSSezNQn3iLgkIh6MiH0Rcc1a7EOStLRVD/eIaAN/ALwD2A28JyJ2r/Z+JElLW4uW+5uAfZn5SGZOA38KXLYG+5EkLWEtwv1c4PHa9BNlXo+IuDoiJiNicmrKy+9K0moa2AeqmXldZk5k5sT4+PigypCkRlqLcH8SOL82fV6ZJ0laJ2sR7v8XuCAidkXEGHAlcNMa7EeStIQ1ubZMRFwK/B7QBj6Vmb95nOWngEdXuLuzge+vcN21ZF3Ls1Hrgo1bm3UtTxPr+qHMXLRfe0NcOKwfETG51IVzBsm6lmej1gUbtzbrWp6TrS6/oSpJDWS4S1IDNSHcrxt0AUuwruXZqHXBxq3NupbnpKpr6PvcJUlHa0LLXZK0gOEuSQ001OE+yEsLR8T5EXFrRNwXEfdGxAfL/N+IiCcj4u7yc2ltnV8vtT4YET+1hrV9LyK+XfY/WeadGRE3R8RDZbi9zI+I+ESp61sRceEa1fQjtWNyd0S8EBEfGsTxiohPRcTTEXFPbd6yj09E7CnLPxQRe9aort+OiAfKvr8cEdvK/J0Rcah23P6wts4/KK//vlJ7X3cxWaKuZb9uq/33ukRdn6/V9L2IuLvMX8/jtVQ2rO/vWHWrp+H7ofqC1MPAa4Ax4JvA7nXc/w7gwjJ+GvAdqksc/wbwy4ssv7vUuAnYVWpvr1Ft3wPOXjDvPwHXlPFrgI+V8UuB/0l1G6OLgNvX6bV7CvihQRwv4K3AhcA9Kz0+wJnAI2W4vYxvX4O63g6MlPGP1eraWV9uwXb+ttQapfZ3rEFdy3rd1uLvdbG6Fjz+n4H/MIDjtVQ2rOvv2DC33Ad6aeHM3J+Zd5bxF4H7WeTqlzWXAX+amYcz87vAPqrnsF4uA/aW8b3A5bX5n8nKbcC2iNixxrVcDDycmcf6VvKaHa/M/BrwzCL7W87x+Sng5sx8JjOfBW4GLlntujLzK5k5WyZvo7pW05JKbadn5m1ZJcRnas9l1eo6hqVet1X/ez1WXaX1fQXwuWNtY42O11LZsK6/Y8Mc7id0aeH1EBE7gTcCt5dZ/7r8e/Wp7r9erG+9CXwlIu6IiKvLvHMyc38Zfwo4ZwB1dV1J7x/doI8XLP/4DOK4/QJVC69rV0TcFRH/OyJ+rMw7t9SyHnUt53Vb7+P1Y8CBzHyoNm/dj9eCbFjX37FhDvcNISJOBf4M+FBmvgBcC7wW+PvAfqp/DdfbWzLzQqq7YX0gIt5af7C0UAZyDmxUF5N7F/DFMmsjHK8egzw+S4mIjwCzwGfLrP3AqzPzjcCHgT+JiNPXsaQN97ot8B56GxDrfrwWyYZ56/E7NszhPvBLC0fEKNWL99nM/BJAZh7IzLnM7AB/xJGuhHWrNzOfLMOngS+XGg50u1vK8On1rqt4B3BnZh4oNQ78eBXLPT7rVl9E/Dzw08B7SyhQuj3+rozfQdWf/bpSQ73rZk3qWsHrtp7HawR4N/D5Wr3rerwWywbW+XdsmMN9oJcWLn161wP3Z+bHa/Pr/dX/BOh+kn8TcGVEbIqIXcAFVB/krHZdWyPitO441Qdy95T9dz9t3wPcWKvrfeUT+4uA52v/Oq6FnhbVoI9XzXKPz18Bb4+I7aVL4u1l3qqKiEuAXwXelZkHa/PHo7pfMRHxGqrj80ip7YWIuKj8jr6v9lxWs67lvm7r+ff6NuCBzJzvblnP47VUNrDev2P9fCo86B+qT5m/Q/Uu/JF13vdbqP6t+hZwd/m5FPhvwLfL/JuAHbV1PlJqfZA+P5E/Rl2voToT4ZvAvd3jApwF3AI8BPwv4MwyP6huaP5wqXtiDY/ZVuDvgDNq89b9eFG9uewHZqj6Ma9ayfGh6gPfV37ev0Z17aPqd+3+jv1hWfafltf3buBO4Gdq25mgCtuHgf9C+Sb6Kte17Ndttf9eF6urzP808C8WLLuex2upbFjX3zEvPyBJDTTM3TKSpCUY7pLUQIa7JDWQ4S5JDWS4S1IDGe6S1ECGuyQ10P8HID1smsq3cq4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "noOfLayers = 3\n",
        "Activations = ['ReLU'] * (noOfLayers+1)\n",
        "\n",
        "params, errors, val_errors = training(X_train, Y_train, X_val, Y_val, Activations, noOfLayers)\n",
        "\n",
        "\n",
        "# print(errors[-1])\n",
        "plt.plot(errors)\n",
        "plt.show()\n",
        "plt.plot(val_errors)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUA8PgbE66lH"
      },
      "source": [
        "Testing the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLAPV3z47Bt-",
        "outputId": "adaaedec-dbec-46f5-af46-6f21790d559d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10.56346071 19.43438512  2.32249372 ...  6.26059837 22.89478489\n",
            "   5.66102375]]\n",
            "[3.7479247]\n"
          ]
        }
      ],
      "source": [
        "y_out, error = testing(X_test, Y_test, params, Activations, noOfLayers)\n",
        "\n",
        "print(y_out)\n",
        "print(error)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
